[
  {
    "question": "The reliability of a measuring tool has following aspects, except:",
    "options": {
      "A": "stability",
      "B": "internal consistency",
      "C": "efficiency",
      "D": "equivalence"
    },
    "answer": "C",
    "explanation": "Why (C) is Correct: Efficiency refers to how cost-effective or time-saving a tool is to administer. While a practical consideration in choosing a tool, it is not a psychometric property that measures the tool's quality of measurement. Reliability specifically refers to the consistency and dependability of a measurement tool—the degree to which it yields the same results on repeated trials.\n\nWhy (A), (B), and (D) are Correct Aspects of Reliability:\n\n(A) Stability: This refers to the tool's consistency over time. It is measured using the test-retest reliability method, where the same test is given to the same people at two different times, and the scores are correlated. A high correlation indicates good stability.\n\n(B) Internal Consistency: This assesses whether all the items on a single test or scale are measuring the same underlying concept. It is typically measured with a statistic called Cronbach's alpha. It's like asking, \"Do all the questions on this depression scale actually relate to depression?\"\n\n(D) Equivalence: This refers to the consistency or agreement between two or more different observers or between alternate forms of a test. It is measured using inter-rater reliability (do two observers score the same event the same way?) or parallel forms reliability (do two different versions of the same test give similar results?).",
    "additional": "Future Test Focus & Additional Concepts:\n\nReliability vs. Validity: This is the most fundamental concept in measurement.\n\nReliability = Consistency. A reliable tool produces the same results again and again.\n\nValidity = Accuracy. A valid tool measures what it is actually supposed to measure.\n\nThe Target Analogy:\n\nReliable but Not Valid: The shots are all clustered together, but they are off-target. (Consistent but wrong).\n\nValid but Not Reliable: The shots are scattered all around the target. (On average, they are centered on the target, but they are not consistent).\n\nReliable AND Valid: The shots are all tightly clustered in the center of the target. (Consistent and accurate - the ideal).\n\nA tool cannot be valid if it is not reliable. If it's not consistent, it can't be accurately measuring anything. However, a tool can be reliable without being valid."
  },
  {
    "question": "The reliability of a measuring tool has following aspects, except:",
    "options": {
      "A": "nominal",
      "B": "ordinal",
      "C": "interval",
      "D": "ratio"
    },
    "answer": "Invalid question (see explanation)",
    "explanation": "This question appears to be a mistake in the exam paper. It repeats the question stem from Q1 but provides answers related to levels of measurement, not aspects of reliability. Assuming the question should have been 'Levels of measurement include all of the following, except:', none of the answers would be correct as A, B, C, and D are all the four standard levels of measurement.\n\nHowever, if we must interpret the question as written ('The reliability... has following aspects, except:'), then all options (A, B, C, D) are incorrect because they are levels of measurement, not aspects of reliability.",
    "additional": "Let's re-purpose this question to teach the concept it was likely intended to test.\n\nConcept: Levels of Measurement (NOIR)\n\n(A) Nominal: The lowest level. Data are in categories that have no inherent order. It's about naming or labeling.\nExamples: Gender (Male/Female), Blood Type (A, B, AB, O), Marital Status (Single, Married, Divorced). You can count them (frequencies), but you can't rank them or do math with them.\n\n(B) Ordinal: Data are in categories that have a meaningful order or rank, but the intervals between the ranks are not equal or known.\nExamples: Pain scale (Mild, Moderate, Severe), Likert scales (Strongly Disagree to Strongly Agree), Level of education (High School, Bachelor's, Master's). You know that 'Severe' is worse than 'Mild,' but you don't know by how much.\n\n(C) Interval: Data have a meaningful order, and the intervals between the values are equal and meaningful. However, there is no true zero point.\nExamples: Temperature in Celsius or Fahrenheit. The difference between 20°C and 30°C is the same as the difference between 70°C and 80°C. But 0°C does not mean the absence of temperature. You can add and subtract, but not multiply or divide (you can't say 40°F is twice as hot as 20°F).\n\n(D) Ratio: The highest level of measurement. It has all the properties of interval data, but it also has a true, meaningful zero point, which represents the complete absence of the quantity being measured.\nExamples: Height, weight, pulse rate, blood pressure, age, money. A weight of 0 kg means no weight. You can perform all mathematical operations (add, subtract, multiply, divide). 100 kg is twice as heavy as 50 kg."
  },
  {
    "question": "Deductive Reasoning is applied in:",
    "options": {
      "A": "Qualitative research",
      "B": "Quantitative research",
      "C": "Action research",
      "D": "Applied research"
    },
    "answer": "B",
    "explanation": "Why (B) is Correct: Deductive reasoning moves from the general to the specific. It starts with a general theory or hypothesis and then tests that hypothesis by collecting specific data. This is the classic scientific method and is the foundation of quantitative research. The process is:\nStart with a Theory.\nFormulate a Hypothesis.\nCollect Observations/Data.\nConfirm or reject the hypothesis.\n\nWhy (A) is Incorrect: Qualitative research typically uses inductive reasoning. Inductive reasoning moves from the specific to the general. The researcher starts by collecting specific observations (e.g., through interviews or field notes) and then looks for patterns in that data to build a broader theory or understanding.",
    "additional": "Future Test Focus & Additional Concepts:\n\nQuantitative vs. Qualitative Research:\n\nQuantitative:\nPurpose: To test hypotheses, look at cause and effect, and make predictions.\nData: Numbers, measurements, statistics.\nApproach: Deductive, objective, structured.\nDesigns: Experimental, quasi-experimental, correlational, descriptive surveys.\n\nQualitative:\nPurpose: To explore ideas, formulate a theory, or understand experiences.\nData: Words, images, observations, narratives.\nApproach: Inductive, subjective, unstructured.\nDesigns: Phenomenology (lived experience), Grounded Theory (developing theory from data), Ethnography (studying culture), Historical research.\n\nMixed-Methods Research: A research approach that combines both quantitative and qualitative methods in a single study to gain a more complete understanding of a research problem."
  },
  {
    "question": "In qualitative research, a guiding principle in deciding sample size is:",
    "options": {
      "A": "Effect size",
      "B": "Number of variables",
      "C": "Data saturation",
      "D": "Sub-group analysis"
    },
    "answer": "C",
    "explanation": "Why (C) is Correct: In qualitative research, the goal is not to generalize to a large population but to gain a deep, rich understanding of a phenomenon. Therefore, sample size is not determined by statistical power calculations. \nInstead, the researcher continues to sample participants until they reach data saturation. This is the point at which collecting more data (e.g., conducting another interview) no longer yields any new information, themes, or insights. The same ideas are simply being repeated.\n\nWhy (A), (B), and (D) are Incorrect: These concepts are all related to quantitative research.\n\n(A) Effect size: A statistical measure of the strength of a relationship between two variables. It is used in power analysis to determine the sample size needed for a quantitative study.\n\n(B) Number of variables: The complexity of a quantitative statistical model can influence the required sample size, but it's not the guiding principle.\n\n(D) Sub-group analysis: This is a statistical analysis performed in quantitative studies to compare outcomes between different subgroups. A larger sample size is needed to have enough power for these analyses.",
    "additional": "Future Test Focus & Additional Concepts:\n\nThe Five Rights of Delegation (In Detail):\n\nRight Task: Is this task appropriate to delegate? It should be routine, have a predictable outcome, require minimal problem-solving, and not involve nursing judgment or assessment.\nRight Circumstance: Is the patient setting appropriate? Is the patient stable? Are the necessary resources and supervision available?\nRight Person: Is this delegate (e.g., a Nursing Assistant, LPN/LVN) competent to perform the task?\nRight Direction/Communication: Did you provide clear instructions, expectations, and patient-specific needs?\nRight Supervision/Evaluation: Did you monitor and follow up on task performance?\n\nIn Qualitative Sampling, always consider Data Saturation—not statistical power."
  },
  {
    "question": "A hypothesis which a researcher tries to disprove is:",
    "options": {
      "A": "Research hypothesis",
      "B": "Null hypothesis",
      "C": "Alternate hypothesis",
      "D": "Positive hypothesis"
    },
    "answer": "B",
    "explanation": "Why (B) is Correct: In statistical hypothesis testing, the conventional approach is to start with the null hypothesis (H₀). The null hypothesis states that there is no relationship or no difference between the variables being studied. For example, \"There is no difference in anxiety scores between patients who receive music therapy and those who do not.\" The researcher then collects data and performs a statistical test to determine if there is enough evidence to reject or disprove the null hypothesis.\n\nWhy (A), (C), and (D) are Incorrect:\n\n(A) Research hypothesis & (C) Alternate hypothesis: These are two names for the same thing (H₁ or Hₐ). This is the hypothesis that the researcher actually believes to be true. It states that there is a relationship or a difference (e.g., \"Patients who receive music therapy will have lower anxiety scores...\"). The researcher seeks to find evidence that supports the alternate hypothesis by disproving the null hypothesis.\n\n(D) Positive hypothesis: This is not a standard term in research methodology.",
    "additional": "Future Test Focus & Additional Concepts:\n\nThe Logic of Hypothesis Testing: You can never prove the alternate hypothesis to be 100% true with statistics. You can only gather enough evidence to show that the null hypothesis is very unlikely to be true. If the probability (the p-value) of observing your data (or more extreme data) is very small if the null hypothesis were true, you reject the null hypothesis in favor of the alternate.\n\nType I and Type II Errors: This is a critical concept linked to hypothesis testing.\n\nType I Error (α): Rejecting a true null hypothesis. This is a \"false positive.\" You conclude there is an effect when there actually isn't one. The probability of making a Type I error is your alpha level (e.g., α = 0.05).\n\nType II Error (β): Failing to reject a false null hypothesis. This is a \"false negative.\" You conclude there is no effect when there actually is one. The probability of this error is Beta (β).\n\nPower: The probability of correctly rejecting a false null hypothesis (Power = 1 - β). It's the ability of a study to detect a real effect if one exists. Increasing your sample size is the most common way to increase the power of a study."
  },
  {
    "question": "When research findings can be applied to the larger population",
    "options": {
      "A": "internal validity",
      "B": "Study reliability",
      "C": "External validity",
      "D": "Study generalization"
    },
    "answer": "C",
    "explanation": "Why (C) is the Best Term: External validity is the formal research term for the extent to which the results of a study can be generalized to other populations, settings, or times. It answers the question, \"Do these findings apply to people outside of my specific study sample?\" Therefore, it is the most technically accurate term for the concept described.\n\nWhy (D) is Also Correct: Study generalization (or generalizability) is a synonym for external validity. It's the lay term for the same concept. In a multiple-choice question where both are options, the more formal term (External Validity) is usually preferred.\n\nWhy (A) and (B) are Incorrect:\n\n(A) Internal validity: This refers to the degree of confidence that the causal relationship being tested is trustworthy and not influenced by other factors or variables. It answers the question, \"Was the research done right? Is the independent variable really the thing causing the change in the dependent variable?\" It is about the quality of the study's design, not its applicability to others.\n\n(B) Study reliability: As discussed before, reliability refers to the consistency of the measurement tool, not the applicability of the study's findings.",
    "additional": "Future Test Focus & Additional Concepts:\n\nThreats to Internal Validity: These are confounding factors that can ruin a study. Be able to recognize them.\n\nHistory: An external event occurs during the study that affects the outcome.\nMaturation: Natural changes in the subjects over time (e.g., they get older, wiser, or more tired).\nTesting: The act of taking a pre-test influences the scores on the post-test.\nInstrumentation: Changes in the measurement tool or observer over time.\nSelection Bias: Differences between the groups being compared that exist from the start. (Randomization is the best defense against this).\nMortality/Attrition: When participants drop out of the study, and the ones who drop out are different from those who remain.\n\nThreats to External Validity:\nSample Characteristics: If the study sample is very different from the larger population (e.g., using only male college students), the results may not generalize.\nSetting Characteristics (Hawthorne Effect): The artificiality of the research setting or the fact that participants know they are being studied can cause them to behave differently than they would in the real world."
  },
  {
    "question": "Test-retest reliability in research involves:-",
    "options": {
      "A": "Two different measurements taken by different observers and then comparing them",
      "B": "Taking two sets of measurements of the same thing some time apart and comparing them",
      "C": "Recruiting participants randomly to the study project",
      "D": "Subjecting one study group to treatment and the other to placebo"
    },
    "answer": "B",
    "explanation": "Why (B) is Correct: This is the precise definition of the test-retest method for assessing reliability. It measures the stability of a tool over time. You administer the tool to a group of participants, wait for a period, and then administer the exact same tool to the same participants again. You then calculate the correlation between the scores from Time 1 and Time 2. A high correlation indicates that the tool is stable and reliable.\n\nWhy (A), (C), and (D) are Incorrect:\n\n(A) ...different observers...: This describes how you measure inter-rater reliability, a form of equivalence.\n\n(C) Recruiting participants randomly...: This describes random sampling, a technique used to increase the external validity (generalizability) of a study. It is not related to reliability.\n\n(D) ...one study group to treatment and the other to placebo: This describes the design of a randomized controlled trial (RCT), the gold standard for testing the effectiveness of an intervention. It relates to the study's internal validity, not its reliability.",
    "additional": "This completes the review of this set. I will proceed to the next research questions."
  },
  {
    "question": "Which of the following classification of research designs is based on the dimension of control over independent variables?",
    "options": {
      "A": "Structured and flexible",
      "B": "Cross-sectional and longitudinal",
      "C": "Retrospective and prospective",
      "D": "Experimental/quasi experimental and non-experimental"
    },
    "answer": "D",
    "explanation": "Why (D) is Correct: The key dimension that separates these three broad categories of quantitative research design is the degree of control the researcher has over the independent variable (IV)—the variable that is manipulated or thought to be the cause.\n\nExperimental Design (True Experiment): The researcher has maximum control. They manipulate the IV (e.g., give a drug to one group and a placebo to another), use randomization to assign subjects to groups, and have a control group. This allows for the strongest causal inferences.\n\nQuasi-Experimental Design: The researcher manipulates the IV, but there is no randomization. For example, comparing a new teaching method in one classroom to the old method in another existing classroom. The lack of randomization weakens the ability to claim cause-and-effect.\n\nNon-Experimental Design: The researcher does not manipulate the IV. They simply observe and measure variables as they naturally exist. Examples include correlational studies or descriptive surveys.",
    "additional": "Why (A), (B), and (C) are Incorrect Classifications Based on Control:\n\n(A) Structured and flexible: This dimension distinguishes quantitative (structured) from qualitative (flexible) research approaches.\n\n(B) Cross-sectional and longitudinal: This dimension classifies designs based on the time frame of data collection. A cross-sectional study collects data at one point in time. A longitudinal study collects data at multiple points over time.\n\n(C) Retrospective and prospective: This also relates to time. A retrospective study looks backward in time from an outcome to a potential cause (e.g., case-control study). A prospective study looks forward in time from a cause to an outcome (e.g., cohort study).\n\nFuture Test Focus & Additional Concepts:\n\nHierarchy of Evidence: This is a ranking system used to describe the strength of research results. It is a critical concept for Evidence-Based Practice (EBP).\n\nLevel I: Systematic Reviews & Meta-Analyses of Randomized Controlled Trials (RCTs). This is the highest level of evidence.\n\nLevel II: Single, well-designed RCTs.\n\nLevel III: Well-designed quasi-experimental studies (controlled trials without randomization).\n\nLevel IV: Well-designed non-experimental studies (case-control, cohort studies).\n\nLevel V: Systematic reviews of descriptive or qualitative studies.\n\nLevel VI: Single descriptive or qualitative study.\n\nLevel VII: Expert opinion or reports of expert committees. This is the lowest level of evidence.\n\nExam Scenario: \"A nurse wants to find the strongest possible evidence for the effectiveness of a new wound care dressing. Which of the following would be the best source?\" (Answer: A systematic review of RCTs)."
  },
  {
    "question": "The primary objective of experimental methodology is:",
    "options": {
      "A": "Ensure external validity",
      "B": "Improve internal validity",
      "C": "To eliminate type I error",
      "D": "To reduce ethical problems"
    },
    "answer": "B",
    "explanation": "Why (B) is Correct: The entire purpose of the strict design features of an experimental methodology (manipulation, randomization, and control) is to improve internal validity. By controlling for confounding variables and eliminating alternative explanations for the outcome, the experimenter can be more confident that the change in the dependent variable was actually caused by the manipulation of the independent variable. It is all about establishing a cause-and-effect relationship.",
    "additional": "Why (A), (C), and (D) are Incorrect:\n\n(A) Ensure external validity: Often, the strict controls of an experiment can reduce external validity. The highly controlled, artificial setting of a lab experiment may not be generalizable to the real world. There is often a trade-off between internal and external validity.\n\n(C) To eliminate type I error: The researcher controls the risk of a Type I error by setting the alpha level (e.g., α = 0.05). It is a statistical decision, not the primary objective of the experimental design itself.\n\n(D) To reduce ethical problems: Experimental research, especially with human subjects, can often increase ethical problems (e.g., the ethics of withholding a potentially beneficial treatment from a control group).\n\nFuture Test Focus & Additional Concepts:\n\nKey Terms in Experimental Research:\n\nIndependent Variable (IV): The variable that is manipulated by the researcher (the intervention, the cause).\n\nDependent Variable (DV): The variable that is measured as the outcome (the effect).\n\nConfounding Variable: An \"extra\" variable that was not accounted for and could be an alternative explanation for the results, thus threatening internal validity.\n\nRandomization (Random Assignment): The process of assigning subjects to groups by chance. This is the most effective way to ensure that the groups are equivalent at the start of the study, thereby controlling for selection bias.\n\nBlinding (or Masking): The process of concealing group allocation from one or more individuals involved in a study.\n\nSingle-blind: The participants don't know which group they are in.\n\nDouble-blind: Neither the participants nor the researchers/data collectors know the group allocation. This is the gold standard for reducing bias."
  },
  {
    "question": "The following is a biased sampling method:-",
    "options": {
      "A": "Cluster",
      "B": "Quota",
      "C": "Stratified random",
      "D": "Systematic"
    },
    "answer": "B",
    "explanation": "Why (B) is Correct: Quota sampling is a non-probability sampling method. In non-probability sampling, the selection of participants is not random, which means that every member of the population does not have an equal chance of being selected. This introduces the potential for bias. In quota sampling, the researcher identifies strata (subgroups) of the population (e.g., 50% male, 50% female) and then fills the quota for each stratum using a non-random method, such as taking the first 50 men and 50 women who walk by. This can lead to a sample that is not representative of the population.",
    "additional": "Why (A), (C), and (D) are Probability (Unbiased) Methods: These are all probability sampling methods, where selection is based on random chance, reducing bias.\n\n(A) Cluster sampling: The population is divided into clusters (e.g., geographical areas like villages or schools). The researcher randomly selects a number of clusters and then includes all individuals within the selected clusters in the sample. It's a probability method, though it may have a larger sampling error than simple random sampling.\n\n(C) Stratified random sampling: The population is divided into strata based on a key characteristic (e.g., age groups). The researcher then takes a random sample from within each stratum. This ensures that the final sample is representative of the population in terms of that characteristic.\n\n(D) Systematic sampling: The researcher selects every kth person from a list (e.g., every 10th patient on a clinic register). As long as the starting point is random and the list is not ordered in a cyclical way that matches the sampling interval, this is a valid probability sampling method.\n\nFuture Test Focus & Additional Concepts:\n\nProbability vs. Non-Probability Sampling: This is a fundamental distinction.\n\nProbability Sampling (Random): Allows for generalization to the population. Used in quantitative research.\n- Simple Random\n- Systematic\n- Stratified\n- Cluster\n\nNon-Probability Sampling (Non-Random): Does not allow for generalization. Prone to bias. Often used in qualitative research or when probability sampling is not feasible.\n- Convenience Sampling: Using whoever is readily available (e.g., patients in my clinic). Most common, but also most biased.\n- Quota Sampling: As described above.\n- Purposive (or Judgmental) Sampling: The researcher hand-picks participants who are considered experts or have specific knowledge about the topic.\n- Snowball Sampling: Participants are asked to recommend other potential participants. Used for hard-to-reach populations.\n\nThis completes this set of research questions."
  },
  {
    "question": "The following is an advantage of close ended questions in a questionnaire:-",
    "option": {
      "A": "Easy to construct",
      "B": "Easy to administer",
      "C": "Responses are limited",
      "D": "Permit greater depth of response"
    },
    "answer": "(B) Easy to administer",
    "explanation": "Why (B) is Correct: Closed-ended questions provide respondents with a pre-set list of answers to choose from (e.g., multiple choice, yes/no, Likert scales). This makes the questionnaire very straightforward and quick for both the respondent to answer and the researcher to administer. More importantly, the data collected is standardized, which makes it very easy to code, enter into a computer, and analyze statistically. This ease of administration and analysis is a primary advantage.\n\nWhy (A), (C), and (D) are Incorrect:\n\n(A) Easy to construct: This is often false. Constructing good, valid, and reliable closed-ended questions and response options can be very difficult and time-consuming. It's much easier to just ask an open-ended question.\n\n(C) Responses are limited: This is a disadvantage, not an advantage. The researcher may miss out on important information or nuances because the respondent cannot express their true opinion if it's not one of the available options.\n\n(D) Permit greater depth of response: This is the primary advantage of open-ended questions, which allow respondents to answer in their own words. Closed-ended questions do the opposite; they limit the depth of the response.",
    "additional": "Questionnaire Design Principles:\n- Use clear and simple language. Avoid jargon and ambiguity.\n- Avoid double-barreled questions (asking two things in one question, e.g., \"Was the nurse friendly and knowledgeable?\").\n- Avoid leading questions that suggest a desired answer.\n- Ensure response options are mutually exclusive and exhaustive.\n- Start with easy, non-threatening questions to build rapport. Place sensitive questions (e.g., about income or personal habits) near the end.\n\nLikert Scale vs. Semantic Differential Scale:\n- Likert Scale: Measures agreement with a statement (e.g., Strongly Agree, Agree, Neutral, Disagree, Strongly Disagree).\n- Semantic Differential Scale: Measures a respondent's feeling about a concept by placing a mark between two bipolar adjectives (e.g., \"Nursing care was: Good ---:---:---:---:--- Bad\")."
  },
  {
    "question": "The best literature in academic terms is a :-",
    "option": {
      "A": "Recent book",
      "B": "Refereed journal article",
      "C": "Conference proceedings",
      "D": "Scientific publication"
    },
    "answer": "(B) Refereed journal article",
    "explanation": "Why (B) is Correct: A refereed journal article (also known as a peer-reviewed journal article) is considered the gold standard for academic and scientific literature. The peer-review process means that before an article is published, it is sent to several other independent experts (peers) in the same field for a rigorous evaluation. They critique the methodology, analysis, and conclusions to ensure the research is valid, significant, and original. This process acts as a critical quality filter.\n\nWhy (A), (C), and (D) are Incorrect:\n\n(A) Recent book: While books can be excellent sources, they often do not undergo the same rigorous, blind peer-review process as journal articles. They can also become outdated more quickly than the rapidly published articles in academic journals.\n\n(C) Conference proceedings: These are often preliminary findings or works in progress. They typically undergo a much less stringent review process than a journal article and are not considered as authoritative.\n\n(D) Scientific publication: This is a very general term. A refereed journal article is a type of scientific publication, but so are books, conference proceedings, and even non-peer-reviewed articles. Option (B) is the most specific and highest quality choice.",
    "additional": "Types of Journal Articles:\n- Primary Source (Original Research): The authors report on research they conducted themselves (e.g., an RCT, a qualitative study). This is the raw evidence.\n- Secondary Source (Review Article): The authors summarize and synthesize the work of other researchers on a particular topic.\n- Literature Review: A narrative summary of the literature.\n- Systematic Review: A highly structured review that uses a rigorous and transparent method to find, appraise, and synthesize all of the available evidence on a specific question.\n- Meta-Analysis: A type of systematic review that uses statistical methods to combine the results of multiple similar quantitative studies (like RCTs) to produce a single, more precise estimate of the effect. This is at the top of the evidence hierarchy."
  },
  {
    "question": "'Emic perspective' refers to:",
    "option": {
      "A": "Outsider's view",
      "B": "Insider's view",
      "C": "Etic perspective",
      "D": "Holistic view"
    },
    "answer": "(B) Insider's view",
    "explanation": "This is a key concept in qualitative research, particularly ethnography. An emic perspective is the perspective of the research participant—the \"insider's\" view. It is the understanding of a culture or experience from within.\n\nAn etic perspective is the perspective of the researcher—the \"outsider's\" view. It is an objective, interpretive understanding from the outside.\n\nThe goal of much qualitative research is to understand and accurately portray the emic perspective.",
    "additional": ""
  },
  {
    "question": "Whereas quantitative research tends to bring out a static picture of social life, qualitative research depicts it as",
    "option": {
      "A": "Symmetrical",
      "B": "Statistical",
      "C": "Processual",
      "D": "Proverbial"
    },
    "answer": "(C) Processual",
    "explanation": "Quantitative research often provides a \"snapshot\" in time (e.g., a cross-sectional survey). Qualitative research, because it involves in-depth interviews, observation over time, and a focus on lived experience, is better able to capture the dynamic, unfolding, and evolving nature of social life. It depicts life as a process, not a static state.",
    "additional": ""
  }
]

